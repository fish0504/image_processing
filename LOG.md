# 作業ログ
研究の作業ログです


## 0105 
行った作業
* dSPACEと画像処理用PC (Ubuntu)と通信するプログラムの移植

### メモ
* Makefileを作ってビルドしたほうが遥かに楽
* std::forwardは左辺参照値を右辺参照にする->使い捨ての変数を関数に渡すときにコピーせずにアドレスの権限を渡すことで速くなる

### よくわからなかったこと
* make_uniqueがどういう要素を行っているか=スマートポインタがよくわかっていない

次にやること
* dSPACEの方でPCから送信した数値が見れるようにする。->接続はできているようなのでアドレストアkはあってそう、プログラム側での設定の問題?
## 0106
UDP通信をしようといろいろ調べながらやったがうまくいかず

## 0107
UDPとdPSACEについて調べまくって相談した
### やったこと
* 送信はできてそうだが、dSPACE側で受信がうまくできていないみたい

### メモ
* LinuxまたはBoostのライブラリがx86系に依存しているから?
  ->Boost以外の方法でUDP通信する  
* 送信するパケットのサイズも送信側と受信側で揃えたが信号は出てこない。
* コネクション自体は確立されてそう(データの速度が表示されているので)

## 0108

### やったこと
* Boostを使わないAPIでUDPの送受信を自分のポートに送信するプログラムを動作させた  
  ->正常に動作した(送信した内容が確認できた)のでやはり受信側の問題?

## 0111

### やったこと
* 受信側のモニタリングのレイアウトを変更、IPアドレスを"10.1.196.179"->"192.168.140.33"に変更してみたが
後者はホストPCからのIPアドレスなのでうまく行かず(送信するとmeasuringが止まる)

## 0112

### やったこと
* レポジトリを整理してカメラ入出力と姿勢推定、ステレオマッチングを並行で動かすmainプログラムをMakefileでビルド

### 次やること
* 現在のプログラムに追加してPythonへのConvert.cppもマッチングの処理の最後に追加、まとめてmainでビルドする
->すべてがうごくようになったmainプログラムをDex-NetのDocker環境へ移植する.

## 0113

### やったこと
* Convert.cpp :=ステレオマッチングの結果をpythoon numpyへ変換する関数を追加、それに応じてMakefileも変更,
推定角度のグラフ描画とは両立せず
* 必要なライブラリ(opencv,Boost,boost_python)をdocker内へコピー、このレポジトリをクローンした。
* dockerを起動してmakeコマンドを実行->エラーが出るライブラリを外からコピーしてDockerコンテナをビルドし直した(これを繰り返した)
### 次にやること
* 0113現在,x86-Linux*/とopencv/lib内のバージョンが異なるライブラリが競合していると思われるエラーが出ている
　opencv系のものは両方のディレクトリにある場合または片方のみある
->x86-Linuxのディレクトリをまるごと削除し、必要なものだけを外から事前にコピーしておく(うまく行かない可能性もある)
#### (代替案)
* OpencvについてはDocker起動後に中でビルドする(バージョンは揃えないといけないので多分4.1)

## 0114

### やったこと
* dex-NetのDocker環境内でこのレポジトリのプログラムをビルドしようと試みていたが、OSとかもっと深い部分でLinkerのエラーが出て解消が難しかったので,Dockerを使わずにDex-Netを動かす方に転換した
->足りないものをいくつかインストールするととりあえず動かすことができた(tensorflowが使えていないので後で使えるようにする)

### 次にすること
* 現在、取得したdepth画像を変換し。mat_numpy.pyを呼び出しているが、呼び出すファイルをmat_numpy.py->examples/policy.pyに変更する
* examples/policy.pyで実行時引数でモデルやcfgを指定している部分を定数にする(指定がなくても画像だけで呼び出せるようにする)

## 0115

### やったこと
* dex-netをboost-pythonを使って関数として呼び出すために、
  * pyenvをつかってdex-netの依存ライブラリをインストール  (pyenvはpy3.6/Pipfileで　$pipenv shell　で起動する)<br>https://qiita.com/sabaku20XX/items/67eb69f006adbbf9c525#apt-update--apt-upgrade
  * パスの変更  
  をおこなった
### 進捗
* dex-netがカメラ入出力のプログラムから渡せるようになった。  
->まだ画像を入力として渡すのと座標を返り値で受け取る部分はできていない。

### 次やること
* boost_python(conver.cpp)でやっていることを把握してpolicy.pyを画像を渡しながら呼び出せるようにする。
* dex-netからの出力を受け取れるようにする(c++側で表示できるようにする)


## 0118

### やったこと
* dex-netへの入力と出力を関数で引数として渡そうとしたが、boost_pythonの問題でうまくいかなかったので、yamlファイルを通して出力をc++側で受け取るようにした。
* policy.pyにはファイル経由で画像を渡すことにする
##### メモ
* yamlファイルはcv::Filestorageで開く場合はヘッダー部分に"%YAML"がないとエラーが出る、書き込みをcv.Filestorageでおこなうと自動で"％YAML”のヘッダーがつく  
* opencvのyaml_tutorial<br>https://docs.opencv.org/master/dd/d74/tutorial_file_input_output_with_xml_yml.html
### 次やること
* UDP通信、ステレオマッチングのキャリブレーションと実験環境のコンフィギュレーションをして、カメラ入力->ステレオマッチングの画像に対してdex-netの出力を得る


## 0119

### やったこと
* キャリブレーションの精度を改善しようと試行錯誤した。
  * 平行化後の画像を見る限り、平行化がうまくいってないように思われる<br>
  ->キャリブレーションのrotate周りなどをしらべる
  * ターゲットの輪郭がうまく出てこない<br>
  ->ターゲットを反射が少ない素材で覆う<br>
  ->光源を別に用意する<br>
  ->カメラの基線長を長くする<br>
 
### つぎにやること
* 上記の->の部分の続きをする


## 0120

### やったこと
* ターゲットを反射が少ない対象で覆う、光源、キャリブレーション、ガウシアンフィルタのパラメータ調整を行った結果、
ターゲットの持ち手と輪郭がうつったデプス画像をかろうじて得ることができた。(disp_results/good_result.png)<br>
(参考URL)
http://opencv.jp/cookbook/opencv_img.html#gaussianblur

### 次やること
* デプス画像は取得できたが、Dex-Netに入力した際にうまくでていない感があるので、うまくできているか、また内部のconfiguration(cfgファイル周り)と公式ドキュメントを見て、
調整すべきパラメータがあるか確認、出力でデプスがきちんと出るようにする

## 0121

### やったこと
* キャリブレーションのカメラパラメータを計算から手動で決定してステレオマッチングを試した
* ハンドで目標値追従無しでつかむ動きを作ってみた
  ->起動に関して、コップ本体部分との接触がありそうなのでそこは注意が必要

### 次にやること

* ハンドの逆運動学を解いて、目標値追従で動けるようにする
* IntelRealsenseをつかってデプス取得、Dex-Netに入力をやる

## 0123

### やったこと
* ハンドでつかむ動作(目標値追従なし)をやってみた

---------------------------------------

## 2021/01/25〜2021/01/31に終わらせること
* UDP通信(dSpaceの人に質問する)
* デプス取得->dex-Net出力->RealSence?
* 実験環境設定(細かい数値の取得)

2021/02/01から実験に入れるようにする

----------------------------------------


## 0125

### やったこと
* realSenseの導入,取得したデプス画像をDex-Netに入力

### 次やること
* セグマスクを作成して、中央付近だけ二値化してそれ以外黒のセグマスクを作成する
->それをともにDex-Netに入力する
