# 作業ログ
研究の作業ログです


## 0105 
行った作業
* dSPACEと画像処理用PC (Ubuntu)と通信するプログラムの移植

### メモ
* Makefileを作ってビルドしたほうが遥かに楽
* std::forwardは左辺参照値を右辺参照にする->使い捨ての変数を関数に渡すときにコピーせずにアドレスの権限を渡すことで速くなる

### よくわからなかったこと
* make_uniqueがどういう要素を行っているか=スマートポインタがよくわかっていない

次にやること
* dSPACEの方でPCから送信した数値が見れるようにする。->接続はできているようなのでアドレストアkはあってそう、プログラム側での設定の問題?
## 0106
UDP通信をしようといろいろ調べながらやったがうまくいかず

## 0107
UDPとdPSACEについて調べまくって相談した
### やったこと
* 送信はできてそうだが、dSPACE側で受信がうまくできていないみたい

### メモ
* LinuxまたはBoostのライブラリがx86系に依存しているから?
  ->Boost以外の方法でUDP通信する  
* 送信するパケットのサイズも送信側と受信側で揃えたが信号は出てこない。
* コネクション自体は確立されてそう(データの速度が表示されているので)

## 0108

### やったこと
* Boostを使わないAPIでUDPの送受信を自分のポートに送信するプログラムを動作させた  
  ->正常に動作した(送信した内容が確認できた)のでやはり受信側の問題?

## 0111

### やったこと
* 受信側のモニタリングのレイアウトを変更、IPアドレスを"10.1.196.179"->"192.168.140.33"に変更してみたが
後者はホストPCからのIPアドレスなのでうまく行かず(送信するとmeasuringが止まる)

## 0112

### やったこと
* レポジトリを整理してカメラ入出力と姿勢推定、ステレオマッチングを並行で動かすmainプログラムをMakefileでビルド

### 次やること
* 現在のプログラムに追加してPythonへのConvert.cppもマッチングの処理の最後に追加、まとめてmainでビルドする
->すべてがうごくようになったmainプログラムをDex-NetのDocker環境へ移植する.

## 0113

### やったこと
* Convert.cpp :=ステレオマッチングの結果をpythoon numpyへ変換する関数を追加、それに応じてMakefileも変更,
推定角度のグラフ描画とは両立せず
* 必要なライブラリ(opencv,Boost,boost_python)をdocker内へコピー、このレポジトリをクローンした。
* dockerを起動してmakeコマンドを実行->エラーが出るライブラリを外からコピーしてDockerコンテナをビルドし直した(これを繰り返した)
### 次にやること
* 0113現在,x86-Linux*/とopencv/lib内のバージョンが異なるライブラリが競合していると思われるエラーが出ている
　opencv系のものは両方のディレクトリにある場合または片方のみある
->x86-Linuxのディレクトリをまるごと削除し、必要なものだけを外から事前にコピーしておく(うまく行かない可能性もある)
#### (代替案)
* OpencvについてはDocker起動後に中でビルドする(バージョンは揃えないといけないので多分4.1)

## 0114

### やったこと
* dex-NetのDocker環境内でこのレポジトリのプログラムをビルドしようと試みていたが、OSとかもっと深い部分でLinkerのエラーが出て解消が難しかったので,Dockerを使わずにDex-Netを動かす方に転換した
->足りないものをいくつかインストールするととりあえず動かすことができた(tensorflowが使えていないので後で使えるようにする)

### 次にすること
* 現在、取得したdepth画像を変換し。mat_numpy.pyを呼び出しているが、呼び出すファイルをmat_numpy.py->examples/policy.pyに変更する
* examples/policy.pyで実行時引数でモデルやcfgを指定している部分を定数にする(指定がなくても画像だけで呼び出せるようにする)

## 0115

### やったこと
* dex-netをboost-pythonを使って関数として呼び出すために、
  * pyenvをつかってdex-netの依存ライブラリをインストール  (pyenvはpy3.6/Pipfileで　$pipenv shell　で起動する)<br>https://qiita.com/sabaku20XX/items/67eb69f006adbbf9c525#apt-update--apt-upgrade
  * パスの変更  
  をおこなった
### 進捗
* dex-netがカメラ入出力のプログラムから渡せるようになった。  
->まだ画像を入力として渡すのと座標を返り値で受け取る部分はできていない。

### 次やること
* boost_python(conver.cpp)でやっていることを把握してpolicy.pyを画像を渡しながら呼び出せるようにする。
* dex-netからの出力を受け取れるようにする(c++側で表示できるようにする)


## 0118

### やったこと
* dex-netへの入力と出力を関数で引数として渡そうとしたが、boost_pythonの問題でうまくいかなかったので、yamlファイルを通して出力をc++側で受け取るようにした。
* policy.pyにはファイル経由で画像を渡すことにする
##### メモ
* yamlファイルはcv::Filestorageで開く場合はヘッダー部分に"%YAML"がないとエラーが出る、書き込みをcv.Filestorageでおこなうと自動で"％YAML”のヘッダーがつく  
* opencvのyaml_tutorial<br>https://docs.opencv.org/master/dd/d74/tutorial_file_input_output_with_xml_yml.html
### 次やること
* UDP通信、ステレオマッチングのキャリブレーションと実験環境のコンフィギュレーションをして、カメラ入力->ステレオマッチングの画像に対してdex-netの出力を得る


## 0119

### やったこと
* キャリブレーションの精度を改善しようと試行錯誤した。
  * 平行化後の画像を見る限り、平行化がうまくいってないように思われる<br>
  ->キャリブレーションのrotate周りなどをしらべる
  * ターゲットの輪郭がうまく出てこない<br>
  ->ターゲットを反射が少ない素材で覆う<br>
  ->光源を別に用意する<br>
  ->カメラの基線長を長くする<br>
 
### つぎにやること
* 上記の->の部分の続きをする


## 0120

### やったこと
* ターゲットを反射が少ない対象で覆う、光源、キャリブレーション、ガウシアンフィルタのパラメータ調整を行った結果、
ターゲットの持ち手と輪郭がうつったデプス画像をかろうじて得ることができた。(disp_results/good_result.png)<br>
(参考URL)
http://opencv.jp/cookbook/opencv_img.html#gaussianblur

### 次やること
* デプス画像は取得できたが、Dex-Netに入力した際にうまくでていない感があるので、うまくできているか、また内部のconfiguration(cfgファイル周り)と公式ドキュメントを見て、
調整すべきパラメータがあるか確認、出力でデプスがきちんと出るようにする

## 0121

### やったこと
* キャリブレーションのカメラパラメータを計算から手動で決定してステレオマッチングを試した
* ハンドで目標値追従無しでつかむ動きを作ってみた
  ->起動に関して、コップ本体部分との接触がありそうなのでそこは注意が必要

### 次にやること

* ハンドの逆運動学を解いて、目標値追従で動けるようにする
* IntelRealsenseをつかってデプス取得、Dex-Netに入力をやる

## 0123

### やったこと
* ハンドでつかむ動作(目標値追従なし)をやってみた

---------------------------------------

## 2021/01/25〜2021/01/31に終わらせること
* UDP通信(dSpaceの人に質問する)
* デプス取得->dex-Net出力->RealSence?
* 実験環境設定(細かい数値の取得)

2021/02/01から実験に入れるようにする

----------------------------------------


## 0125

### やったこと
* realSenseの導入,取得したデプス画像をDex-Netに入力

### 次やること
* セグマスクを作成して、中央付近だけ二値化してそれ以外黒のセグマスクを作成する
->それをともにDex-Netに入力する

## 0126

### 次やること
* UDP通信ができない原因を特定する
  ->Ubuntu側の設定? dSpace側の設定? ポートの問題?
  ->windowsのもとのプログラムを動かすこと(=ルービックキューブのプログラムで通信が正しくできるか調べる)をやろうとしたが、<br>
  ds1007ではないような記述があったので別のプログラムで、windowsからUDP通信を試みてみる


## 0127

### やったこと
* UDP通信ができない原因を探すため、windowsとLinux側で互いにUDP通信ができるか調べたがうまくいかず
* simulinkのブロックの問題?

### 次にやること
* UDPの原因究明というか通信をしたいので、まずはdSpaceではなくPCtoPCで通信できるか調べる<br>
    ->現在使っているプログラムに問題があるかどうかを調べる


## 0128

### やったこと
* UDP通信ができない原因を探す
    ->肥後さんの修論を確認したところルービックキューブはDS1007ではないので<br>そのせいでsimulinkのブロックがうまく機能していない可能性あり<br>->マニュアル等をみてversion切替時に注意する点や依存してそうな関数を探す
    
* dexnetにrealsenseの画像を入力して出力を得るために、pythonでセグマスク等を作成して、入力のパラメータ調整等をおこなった
    ->指定以上の距離はマスクするなどした<br>
    https://qiita.com/protocol1964/items/941f52297afb3353d1b7#%E5%88%9D%E6%9C%9F%E5%8C%96<br>
    いままでうまくいかなかったのはカメラパラメータのせいだと思っていたが、
    実際はc++で書いたコードでdepthのカラーマップに対してcvtcolorでgrayに変換したあたりで数値が本来のものと変わっていたと思われる


## 0129

UDP通信の問題が解決した

原因はローカルIPアドレスの設定だった

rubik hand はもともとds1007以前のもので
local IP : "10.1.x.y"となっていた.


ホストPCとds1007のアドレス
| 装置名 |IPアドレス  |
| -------- | -------- | 
| ds1007のホストアドレス| "192.168.140.7"|
| ホストPC(windows)     |"192.168.140.33"     | 

ホストpcのIPアドレスは"192.168.140.x"(xは7以外で255以下なら何でもいい)　今回は("192.168.140.33")
と設定していた。<br>

それを踏まえて以下のように設定し直した
| 装置名 |IPアドレス  | 
| -------- | -------- |
| 画像処理用pc (Ubuntu) | "192.168.140.10" |
| 画像処理pcのプログラムの送信先アドレス    |"192.168.140.9"   |
| simulink ethernetブロックのアドレス　 |"192.168.140.9"
### 注意点
*　サブネットマスクでグループ分けされているので、ホストPC,ホストアドレスと同じグループになるように "192.168."まではそろえる<br>
    https://livra.geolocation.co.jp/iplearning/214/
*　Ehternetのブロックはホストアドレスとは別のものを設定すること<br>->"192.168.140.7"設定するとうまくいかない


### やったこと
* udp通信がつながったので、実際にデータを送信、角度推定を並列で行いながらUDPで送信して値の変化を確認した。
* convert.cppからdexnetの呼び出しとrealsenseでのデプスとRGB画像の取得を実装した(=use_py)

### 次にやること


* ハンドの逆運動学(=適当に目標値固定で逆運動学で正しく動くようにする)
* コンフィギュレーションを設定して把持位置から目標値への変換の計算式を導出する
